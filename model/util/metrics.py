import math
import numpy as np
from sklearn import metrics
from sklearn.metrics import roc_auc_score
import torch
import torch.nn as nn


def psnr_1(output, target):
    loss_fn = nn.MSELoss(reduction='none')
    loss_pixel = loss_fn(output, target).mean().item()
    # loss_pixel = torch.mean(loss_pixel).item()
    psnr = 10 * math.log10(1 / loss_pixel)
    return psnr


def psnr_error(gen_frames, gt_frames):
    """
    Computes the Peak Signal to Noise Ratio error between the generated images and the ground
    truth images.
    @param gen_frames: A tensor of shape [batch_size, 3, height, width]. The frames generated by the
                       generator model.
    @param gt_frames: A tensor of shape [batch_size, 3, height, width]. The ground-truth frames for
                      each frame in gen_frames.
    @return: A scalar tensor. The mean Peak Signal to Noise Ratio error over each frame in the
             batch.
    """
    shape = list(gen_frames.shape)
    num_pixels = (shape[1] * shape[2] * shape[3])
    gt_frames = (gt_frames + 1.0) / 2.0  # if the generate ouuput is sigmoid output, modify here.
    gen_frames = (gen_frames + 1.0) / 2.0
    square_diff = (gt_frames - gen_frames) ** 2
    batch_errors = 10 * math.log10(1. / ((1. / num_pixels) * torch.sum(square_diff, [1, 2, 3])))
    return torch.mean(batch_errors)


def psnr_frame(gen_frames, gt_frames, hat=True):
    """
    Computes the Peak Signal to Noise Ratio error between the generated images and the ground
    truth images.
    @param gen_frames: A tensor of shape [batch_size, 3, width, height]. 
                       The frames generated by the generator model.
    @param gt_frames: A tensor of shape [batch_size, 3, width, height]. 
                      The ground-truth frames for each frame in gen_frames.
    @return: A scalar tensor. The mean Peak Signal to Noise Ratio error over each frame in the batch.
    """
    gen_frames = gen_frames.detach().cpu()
    gt_frames = gt_frames.detach().cpu()
    batch_num = gen_frames.shape[0]
    batch_errors = 0.0
    for i in range(batch_num):
        num_pixels = gen_frames[i].numel()
        if hat:
            max_val = gen_frames[i].max()
        else:
            max_val = gt_frames[i].max()
        square_diff = (gt_frames[i] - gen_frames[i]) ** 2
        # log_value = torch.log10(max_val ** 2 / ((1. / num_pixels) * torch.sum(square_diff)))
        log_value = torch.log10(max_val / ((1. / num_pixels) * torch.sum(square_diff)))
        image_errors = 10 * log_value
        batch_errors += image_errors

    batch_errors = torch.div(batch_errors, batch_num)
    return batch_errors


def psnr_patch(gen_frames, gt_frames, patch_size=(32, 32), stride=16):
    """
    Computes the Peak Signal to Noise Ratio error between the generated images and the ground
    truth images.
    @param gen_frames: A tensor of shape [batch_size, 3, width, height]. 
                       The frames generated by the generator model.
    @param gt_frames: A tensor of shape [batch_size, 3, width, height]. 
                      The ground-truth frames for each frame in gen_frames.
    @return: A scalar tensor. The mean Peak Signal to Noise Ratio error over each frame in the batch.
    """
    gen_frames = gen_frames.detach().cpu()
    gt_frames = gt_frames.detach().cpu()
    batch_num = gen_frames.shape[0]
    cols = gen_frames.shape[2]  # width
    rows = gen_frames.shape[3]  # height
    batch_errors = 0.0
    for i in range(batch_num):
        patch_scores = []
        for r in range(0, rows, stride):
            for c in range(0, cols, stride):
                gen_patch = gen_frames[:, :, r:r + patch_size[0], c:c + patch_size[1]]
                gt_patch = gt_frames[:, :, r:r + patch_size[0], c:c + patch_size[1]]
                psnr = psnr_frame(gen_patch, gt_patch)
                patch_scores.append(psnr)
        # Calculate the frame-level anomaly score (e.g., using mean or max)
        frame_score = torch.mean(torch.stack(patch_scores))
        batch_errors += frame_score

    batch_errors = torch.div(batch_errors, batch_num)
    return batch_errors


# ================================================================================
# Code from https://github.com/vt-le/astnet
# ================================================================================
def psnr_park(mse):
    return 10 * math.log10(1 / mse)


# Giá trị của PSNR càng cao thì mức độ bất thường càng thấp
# Nghĩa là: Giá trị của PSNR càng cao thì frame càng bình thường
def psnr_normalized(psnr, max_psnr, min_psnr):
    return (psnr - min_psnr) / (max_psnr - min_psnr)


def minmax_normalization(x, max_val, min_val, eps=1e-6):
    denom = max_val - min_val
    if denom < eps:
        return np.zeros_like(x)  # hoặc x - min_val
    return (x - min_val) / denom


def calculate_auc(pf, video_psnr, video_labels):
    scores = np.array([], dtype=np.float64)
    labels = np.array([], dtype=np.int64)

    for i in range(len(video_psnr)):
        score = 1 - minmax_normalization(video_psnr[i],
                                         np.max(video_psnr[i]),
                                         np.min(video_psnr[i]))
        scores = np.concatenate((scores, score), axis=0)
        labels = np.concatenate((labels, video_labels[i][pf:]), axis=0)
    assert scores.shape == labels.shape, f'Ground truth has {labels.shape[0]} frames, BUT got {scores.shape[0]} detected frames!'
    # pos_label=1: The label of the positive class (anomaly).
    fpr, tpr, thresholds = metrics.roc_curve(labels, scores, pos_label=1)
    auc = metrics.auc(fpr, tpr)

    # similar, we can Calculate AUC-ROC by the following function:
    # auc = metrics.roc_auc_score(labels, scores)
    return auc, fpr, tpr, thresholds


def get_optimal_threshold(fpr, tpr, thresholds):
    # https://stackoverflow.com/questions/28719067/roc-curve-and-cut-off-point-python
    # The optimal cut off point would be where “true positive rate” is high and the “false positive rate” is low.
    optimal_idx = np.argmax(tpr - fpr)
    optimal_threshold = thresholds[optimal_idx]
    # gitprint(f'optimal_idx = {optimal_idx}; optimal_threshold = {optimal_threshold}')
    return optimal_idx, optimal_threshold


def cal_auc_psnr_feas(video_psnr, video_feas_distance, video_labels, alpha=0.6):
    """
    Calculate AUC scores for model: MNAD_Pred, MNAD_Pred (AE with memory)
    """
    scores = np.array([], dtype=np.float64)
    labels = np.array([], dtype=np.int64)

    print(f'len(video_psnr) = {len(video_psnr)}')
    print(f'len(feas_distance_list) = {len(video_feas_distance)}')
    print(f'len(video_labels) = {len(video_labels)}')
    for i in range(len(video_psnr)):  # the number of testing videos
        score_psnr = minmax_normalization(video_psnr[i],
                                          np.max(video_psnr[i]),
                                          np.min(video_psnr[i]))
        score_feas_distance = minmax_normalization(video_feas_distance[i],
                                                   np.max(video_feas_distance[i]),
                                                   np.min(video_feas_distance[i]))
        score = alpha * (1 - score_psnr) + (1.0 - alpha) * score_feas_distance

        # score is anomaly scores of frames in video i-th
        scores = np.concatenate((scores, score), axis=0)
        labels = np.concatenate((labels, video_labels[i]), axis=0)
        if scores.shape[0] != labels.shape[0]:
            # avenue: Video_id =8,9,..., 20 => folder 09
            # error because:  .ipynb_checkpoints
            print(f"================>>>> Video_id ={i} ")

    assert scores.shape == labels.shape, f'Ground truth has {labels.shape[0]} frames, BUT got {scores.shape[0]} detected frames!'
    # pos_label=1: The label of the positive class (anomaly).
    # print(f'len(scores) = {len(scores)},\n scores = {scores}')
    # print(f'len(labels) = {len(labels)},\n labels = {labels}')
    fpr, tpr, thresholds = metrics.roc_curve(labels, scores, pos_label=1)
    auc = metrics.auc(fpr, tpr)

    # similar, we can Calculate AUC-ROC by the following function:
    # auc = metrics.roc_auc_score(labels, scores)

    # scores: is a list of anomaly scores of all videos
    print('scores.shape =', scores.shape)  # scores.shape = (1962,)
    print('labels.shape =', labels.shape)  # labels.shape = (1962,)
    # score_list: is a list of anomaly scores of each video

    optimal_idx, optimal_threshold = get_optimal_threshold(fpr, tpr, thresholds)
    return auc, fpr, tpr, optimal_idx, optimal_threshold, labels, scores


def calculate_anomaly_scores_MNAD(frame_psnr, frame_feas_distance, alpha=0.6):
    score_psnr = minmax_normalization(frame_psnr,
                                      np.max(frame_psnr),
                                      np.min(frame_psnr))
    score_feas_distance = minmax_normalization(frame_feas_distance,
                                               np.max(frame_feas_distance),
                                               np.min(frame_feas_distance))

    # score is anomaly scores of frames in video i-th
    scores = alpha * (1 - score_psnr) + (1.0 - alpha) * score_feas_distance
    return scores


def calculate_eer(fpr, fnr):
    """
    Calculate the Equal Error Rate (EER) from an ROC curve.
    
    Parameters:
    - fpr (numpy array): False Positive Rate values.
    - fnr (numpy array): False Negative Rate values.
    
    Returns:
    - eer (float): Equal Error Rate.
    """
    # Find the point on the ROC curve where FPR equals FNR
    eer_index = np.argmin(np.abs(fpr - fnr))

    # Calculate the EER
    eer = (fpr[eer_index] + fnr[eer_index]) / 2.0

    return eer


def calculate_accuracy(fpr, tpr, idx):
    print(f'tpr[{idx}] = {tpr[idx]}')
    print(f'fpr[{idx}] = {fpr[idx]}')
    accuracy = (tpr[idx] + (1 - fpr[idx])) / 2  # Accuracy = (TPR + TNR) / 2
    return accuracy


def calculate_f1_score(fpr, tpr, idx):
    print(f'tpr[{idx}] = {tpr[idx]}')
    print(f'fpr[{idx}] = {fpr[idx]}')
    precision = tpr[idx] / (tpr[idx] + fpr[idx]) if (tpr[idx] + fpr[idx]) > 0 else 0
    recall = tpr[idx]  # Recall = TPR
    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    return f1_score


def mse_error_frame(output, target):
    loss_func_mse = nn.MSELoss(reduction='none')
    error = loss_func_mse((output[0] + 1) / 2, (target[0] + 1) / 2)
    return error


def test_rect():
    video_labels = []
    ##video_labels.append([0])
    # video_labels.append([1])
    # video_labels.append([0, 0])
    video_labels.append([1, 1])
    video_labels.append([1, 0])
    video_labels.append([0, 1])

    video_labels.append([0, 1, 1])
    video_labels.append([0, 0, 1, 1])
    video_labels.append([0, 0, 1, 1, 0])
    video_labels.append([0, 0, 1, 1, 0, 0])
    video_labels.append([0, 0, 1, 1, 0, 0, 1])
    video_labels.append([0, 0, 1, 1, 0, 0, 1, 1])

    video_labels.append([1, 1, 1, 0, 0, 0, 1, 1, 0, 0])
    video_labels.append([1, 1, 1, 0, 0, 0, 1, 1, 0, 1])
    video_labels.append([1, 1, 1, 0, 0, 0, 1, 0, 0, 1])
    video_labels.append([1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1])
    video_labels.append([1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0])
    video_labels.append([1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0])

    print('video_labels =', video_labels)
    for i in range(len(video_labels)):
        get_anomaly_rectanges(video_labels, i)


def get_anomaly_rectanges(frame_labels):
    """
    frame_labels: a list of labels of frames in a video
    """
    rectangles_start = []
    rectangles_end = []
    end = 0
    anom_status = False
    # print("============================")
    # print(f'video_id = {video_id}')
    # print(f'len(label_video) = {len(label_video)}')
    # print(f'label_video = {label_video}')
    for i in range(0, len(frame_labels)):
        if not anom_status:
            if frame_labels[i] == 1:
                anom_status = True
                rectangles_start.append(i)
                end = i
            if i == (len(frame_labels) - 1):
                rectangles_end.append(i)
        else:
            if frame_labels[i] == 1:
                end = i
            else:
                anom_status = False
                rectangles_end.append(end)
            if i == (len(frame_labels) - 1):
                rectangles_end.append(i)

    # print_anomaly_rectangles(rectangles_start, rectangles_end)
    return rectangles_start, rectangles_end


def print_anomaly_rectangles(rectangles_start, rectangles_end):
    for r_start, r_end in zip(rectangles_start, rectangles_end):
        print(f'r_start:{r_start}, r_end:{r_end}')